{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./FastVGGT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "505cd6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1932219/2402874340.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/home/serverai/ltdoanh/VLA_fintuning/FastVGGT/model_tracker_fixed_e20.pt\", map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "from vggt.models.vggt import VGGT  \n",
    "import torch  \n",
    "  \n",
    "# Load model v·ªõi checkpoint  \n",
    "model = VGGT(merging=0, vis_attn_map=True)  # FastVGGT mode  \n",
    "ckpt = torch.load(\"./FastVGGT/model_tracker_fixed_e20.pt\", map_location=\"cpu\")  \n",
    "model.load_state_dict(ckpt, strict=False)  \n",
    "model = model.cuda().eval()  \n",
    "model = model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554be86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è  Found 25 images\n"
     ]
    }
   ],
   "source": [
    "from vggt.utils.eval_utils import (\n",
    "    load_poses,\n",
    "    get_vgg_input_imgs,\n",
    "    get_sorted_image_paths,\n",
    "    build_frame_selection,\n",
    "    load_images_rgb,\n",
    "    infer_vggt_and_reconstruct,\n",
    "    evaluate_scene_and_save,\n",
    ")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "color_dir = Path(\"/home/serverai/ltdoanh/VLA_fintuning/vggt/examples/kitchen/images\")\n",
    "image_paths = get_sorted_image_paths(color_dir)\n",
    "if len(image_paths) == 0:\n",
    "        print(f\"‚ùå Error: No images found in {color_dir}\")\n",
    "\n",
    "print(f\"üñºÔ∏è  Found {len(image_paths)} images\")\n",
    "num_frames = min(len(image_paths), 10)\n",
    "selected_frame_ids = list(range(num_frames))\n",
    "image_paths = image_paths[:num_frames]\n",
    "images = load_images_rgb(image_paths)\n",
    "frame_ids = selected_frame_ids\n",
    "images_array = np.stack(images)\n",
    "vgg_input, patch_width, patch_height = get_vgg_input_imgs(images_array)\n",
    "model.update_patch_dimensions(patch_width, patch_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8955c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force use of bf16 dtype\n",
    "dtype = torch.bfloat16\n",
    "depth_conf_thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b4b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Start inference and reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serverai/ltdoanh/VLA_fintuning/FastVGGT/vggt/utils/eval_utils.py:660: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=dtype):\n",
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 1.7156 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 1.1484 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.3189 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 3.2109 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 1.0896 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 0.9439 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.2631 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.3227 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 1.0904 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 0.9387 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.2565 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.3043 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 1.0074 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 1.0478 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.3436 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.4270 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 1.0860 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 1.0747 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.4269 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.6063 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 0.9352 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 1.0814 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.2826 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.3293 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 0.9364 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 0.9066 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.2417 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.0988 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 0.8812 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 0.9020 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.2471 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.0393 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 1.0177 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 1.1717 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.3573 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.5657 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 0.9333 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 0.9634 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.2535 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.1641 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:4096 processed in 1.2575 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4096:8192 processed in 1.0374 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8192:9300 processed in 0.2516 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 2.5666 seconds\n"
     ]
    }
   ],
   "source": [
    "# Inference + Reconstruction\n",
    "print(f\"üöÄ Start inference and reconstruction...\")\n",
    "(\n",
    "    extrinsic_np,\n",
    "    intrinsic_np,\n",
    "    all_world_points,\n",
    "    all_point_colors,\n",
    "    all_cam_to_world_mat,\n",
    "    inference_time_ms,\n",
    ") = infer_vggt_and_reconstruct(\n",
    "    model, vgg_input, dtype, depth_conf_thresh, image_paths\n",
    ")\n",
    "print(f\"‚è±Ô∏è  Inference time: {inference_time_ms:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad242c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_output_path = \"/home/serverai/ltdoanh/VLA_fintuning/output\"\n",
    "merged_point_cloud = np.vstack(all_world_points)\n",
    "merged_colors = (\n",
    "    np.vstack(all_point_colors).astype(np.uint8)\n",
    "    if all_point_colors is not None and len(all_point_colors) > 0\n",
    "    else None\n",
    ")\n",
    "print(\n",
    "    f\"üìä Merged point clouds: {len(all_world_points)} frames, total {len(merged_point_cloud)} points\"\n",
    ")\n",
    "\n",
    "# If too many points, randomly sample 100000 points\n",
    "max_points = 100000\n",
    "if len(merged_point_cloud) > max_points:\n",
    "    print(\n",
    "        f\"üîΩ Too many points, randomly sampling {max_points} points...\"\n",
    "    )\n",
    "    # Randomly choose indices\n",
    "    indices = np.random.choice(\n",
    "        len(merged_point_cloud), size=max_points, replace=False\n",
    "    )\n",
    "    merged_point_cloud = merged_point_cloud[indices]\n",
    "    if merged_colors is not None:\n",
    "        merged_colors = merged_colors[indices]\n",
    "    print(\n",
    "        f\"‚úÖ Sampling done, kept {len(merged_point_cloud)} points\"\n",
    "    )\n",
    "\n",
    "# Save as PLY (with color)\n",
    "with open(points_output_path, \"w\") as f:\n",
    "    f.write(\"ply\\n\")\n",
    "    f.write(\"format ascii 1.0\\n\")\n",
    "    f.write(f\"element vertex {len(merged_point_cloud)}\\n\")\n",
    "    f.write(\"property float x\\n\")\n",
    "    f.write(\"property float y\\n\")\n",
    "    f.write(\"property float z\\n\")\n",
    "    if merged_colors is not None:\n",
    "        f.write(\"property uchar red\\n\")\n",
    "        f.write(\"property uchar green\\n\")\n",
    "        f.write(\"property uchar blue\\n\")\n",
    "    f.write(\"end_header\\n\")\n",
    "    if merged_colors is None:\n",
    "        for point in merged_point_cloud:\n",
    "            if not (np.isnan(point).any() or np.isinf(point).any()):\n",
    "                f.write(\n",
    "                    f\"{point[0]:.6f} {point[1]:.6f} {point[2]:.6f}\\n\"\n",
    "                )\n",
    "    else:\n",
    "        for point, color in zip(merged_point_cloud, merged_colors):\n",
    "            # Check point validity\n",
    "            if not (np.isnan(point).any() or np.isinf(point).any()):\n",
    "                r = int(np.clip(color[0], 0, 255))\n",
    "                g = int(np.clip(color[1], 0, 255))\n",
    "                b = int(np.clip(color[2], 0, 255))\n",
    "                f.write(\n",
    "                    f\"{point[0]:.6f} {point[1]:.6f} {point[2]:.6f} {r} {g} {b}\\n\"\n",
    "                )\n",
    "\n",
    "print(f\"üíæ Point cloud saved to: {points_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
